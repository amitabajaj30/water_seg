{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "The dataset utilized here is available on Kaggle. \n",
        "https://www.kaggle.com/datasets/gvclsu/water-segmentation-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4lp67FZotc2"
      },
      "source": [
        "Resize the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lxLP2MEox-I"
      },
      "outputs": [],
      "source": [
        "#resize image\n",
        "import os, sys\n",
        "from PIL import Image\n",
        "size = 512, 512\n",
        "files=os.listdir(\"C:\\\\Users\\\\amita.bajaj\\\\Desktop\\\\water_semantic_segmenation\\\\new_data_aug\\\\images\")\n",
        "for file in files:\n",
        "    im = Image.open(\"C:\\\\Users\\\\amita.bajaj\\\\Desktop\\\\water_semantic_segmenation\\\\new_data_aug\\\\images\\\\\"+file)\n",
        "    #width, height = im.size\n",
        "    #if(width>=512 and height>=512):\n",
        "    im = im.resize(size, Image.ANTIALIAS)\n",
        "    im.save(\"C:\\\\Users\\\\amita.bajaj\\\\Desktop\\\\water_semantic_segmenation\\\\new_data_aug\\\\resized\\\\images\\\\\"+str(file.split(\".\")[0])+\".png\", \"PNG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us-nTuiCo0Fv"
      },
      "source": [
        "Renaming the files to follow a particular format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNO4-O2XpBnm"
      },
      "outputs": [],
      "source": [
        "#Renaming the files\n",
        "import os\n",
        "\n",
        "directory = 'C:\\\\Users\\\\amita.bajaj\\\\Desktop\\\\water_semantic_segmenation\\\\new_data_aug\\\\images'\n",
        "\n",
        "# List all the files in the directory\n",
        "files = os.listdir(directory)\n",
        "\n",
        "# Iterate through each file in the directory\n",
        "for index, file in enumerate(files):\n",
        "    # Check if the file is an image file\n",
        "    if file.endswith('.jpg') or file.endswith('.png'):\n",
        "        # Construct the new file name\n",
        "        new_file_name = f'{index}-water.jpg'\n",
        "        # Rename the file\n",
        "        os.rename(os.path.join(directory, file), os.path.join(directory, new_file_name))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyjM_U4ipCtH"
      },
      "source": [
        "Randomly shuffling the Data and splitting into Train Test and Validation Sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtl3Wq0zpNJ4"
      },
      "outputs": [],
      "source": [
        "import os, random, shutil\n",
        "\n",
        "#Prompting user to enter number of files to select randomly along with directory\n",
        "source=input(\"Enter the Source Directory : \")\n",
        "dest=input(\"Enter the Destination Directory : \")\n",
        "no_of_files=int(input(\"Enter The Number of Files To Select : \"))\n",
        "\n",
        "print(\"%\"*25+\"{ Details Of Transfer }\"+\"%\"*25)\n",
        "print(\"\\n\\nList of Files Moved to %s :-\"%(dest))\n",
        "\n",
        "#Using for loop to randomly choose multiple files\n",
        "for i in range(no_of_files):\n",
        "    #Variable random_file stores the name of the random file chosen\n",
        "    random_file=random.choice(os.listdir(source))\n",
        "    print(\"%d} %s\"%(i+1,random_file))\n",
        "    source_file=\"%s/%s\"%(source,random_file)\n",
        "    dest_file=dest\n",
        "    #\"shutil.move\" function moves file from one directory to another\n",
        "    shutil.move(source_file,dest_file)\n",
        "\n",
        "print(\"\\n\\n\"+\"$\"*33+\"[ Files Moved Successfully ]\"+\"$\"*33)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMvxf3jopYE3"
      },
      "source": [
        "Converting masks files into Json Format \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5JixE98poS0"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import json\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "\n",
        "#from src.create_annotations import (create_image_annotation, create_annotation_format, find_contours,\n",
        "                                    #get_coco_json_format, create_category_annotation)\n",
        "\n",
        "# Label ids of the dataset\n",
        "category_ids = {\"water\": 1}\n",
        "\n",
        "MASK_EXT = 'png'\n",
        "ORIGINAL_EXT = 'png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oXTci2SppA5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "\n",
        "image_id = 0\n",
        "\n",
        "\n",
        "def find_contours(sub_mask):\n",
        "    gray = cv2.cvtColor(sub_mask, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
        "\n",
        "\n",
        "def create_category_annotation(category_dict):\n",
        "    category_list = []\n",
        "    for key, value in category_dict.items():\n",
        "        category = {\"id\": value, \"name\": key, \"supercategory\": key}\n",
        "        category_list.append(category)\n",
        "    return category_list\n",
        "\n",
        "\n",
        "def create_image_annotation(file_name, width, height):\n",
        "    global image_id\n",
        "    image_id += 1\n",
        "    return {\n",
        "        \"id\": image_id,\n",
        "        \"width\": width,\n",
        "        \"height\": height,\n",
        "        \"file_name\": file_name,\n",
        "    }\n",
        "\n",
        "\n",
        "def create_annotation_format(contour, image_id_, category_id, annotation_id):\n",
        "    return {\n",
        "        \"iscrowd\": 0,\n",
        "        \"id\": annotation_id,\n",
        "        \"image_id\": image_id_,\n",
        "        \"category_id\": category_id,\n",
        "        \"bbox\": cv2.boundingRect(contour),\n",
        "        \"area\": cv2.contourArea(contour),\n",
        "        \"segmentation\": [contour.flatten().tolist()],\n",
        "    }\n",
        "\n",
        "\n",
        "def get_coco_json_format():\n",
        "    return {\n",
        "        \"info\": {},\n",
        "        \"licenses\": [],\n",
        "        \"images\": [{}],\n",
        "        \"categories\": [{}],\n",
        "        \"annotations\": [{}],\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic1TLjStpstp"
      },
      "outputs": [],
      "source": [
        "# Get \"images\" and \"annotations\" info\n",
        "def images_annotations_info(maskpath):\n",
        "    annotation_id = 0\n",
        "    annotations = []\n",
        "    images = []\n",
        "\n",
        "    for category in category_ids.keys():\n",
        "        for mask_image in glob.glob(os.path.join(maskpath, category, f'*.{MASK_EXT}')):\n",
        "            original_file_name = f'{os.path.basename(mask_image).split(\".\")[0]}.{ORIGINAL_EXT}'\n",
        "            mask_image_open = cv2.imread(mask_image)\n",
        "            height, width, c = mask_image_open.shape\n",
        "            print(mask_image)\n",
        "\n",
        "            if original_file_name not in map(lambda img: img['file_name'], images):\n",
        "                image = create_image_annotation(file_name=original_file_name, width=width, height=height)\n",
        "                images.append(image)\n",
        "            else:\n",
        "                image = [element for element in images if element['file_name'] == original_file_name][0]\n",
        "\n",
        "            contours = find_contours(mask_image_open)\n",
        "\n",
        "            for contour in contours:\n",
        "                annotation = create_annotation_format(contour, image['id'], category_ids[category], annotation_id)\n",
        "                if annotation['area'] > 0:\n",
        "                    annotations.append(annotation)\n",
        "                    annotation_id += 1\n",
        "\n",
        "    return images, annotations, annotation_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf3iGbaJpvBu"
      },
      "outputs": [],
      "source": [
        "#Create annotations for images\n",
        "if __name__ == \"__main__\":\n",
        "    coco_format = get_coco_json_format()  # Get the standard COCO JSON format\n",
        "    \n",
        "    for keyword in [\"valid\", \"train\"]:\n",
        "        mask_path = f\"dataset/{keyword}_mask/\"\n",
        "        print(mask_path)\n",
        " \n",
        "        print(\"mask path\",mask_path)\n",
        "        # Create category section\n",
        "        coco_format[\"categories\"] = create_category_annotation(category_ids)\n",
        "\n",
        "        # Create images and annotations sections\n",
        "        coco_format[\"images\"], coco_format[\"annotations\"], annotation_cnt = images_annotations_info(mask_path)\n",
        "\n",
        "        with open(f\"dataset/{keyword}.json\", \"w\") as outfile:\n",
        "            json.dump(coco_format, outfile, sort_keys=True, indent=4)\n",
        "\n",
        "        print(\"Created %d annotations for images in folder: %s\" % (annotation_cnt, mask_path))\n",
        "        \n",
        "        \n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
